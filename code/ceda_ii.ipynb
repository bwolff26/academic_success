{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31b5a91",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "It dawned on me that this is why I thought of the aptly named notebooks when I want to explore new things. In short, I'm lookng at other's code and seeing what I can garner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef4f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcad048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76518, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Marital status  Application mode  Application order  Course  \\\n",
       "0   0               1                 1                  1    9238   \n",
       "1   1               1                17                  1    9238   \n",
       "2   2               1                17                  2    9254   \n",
       "3   3               1                 1                  3    9500   \n",
       "4   4               1                 1                  2    9500   \n",
       "\n",
       "   Daytime/evening attendance  Previous qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           1                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  ...  \\\n",
       "0                           126.0            1                       1  ...   \n",
       "1                           125.0            1                      19  ...   \n",
       "2                           137.0            1                       3  ...   \n",
       "3                           131.0            1                      19  ...   \n",
       "4                           132.0            1                      19  ...   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0                                    6   \n",
       "1                                    0                                    6   \n",
       "2                                    0                                    6   \n",
       "3                                    0                                    8   \n",
       "4                                    0                                    7   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       7   \n",
       "1                                       9   \n",
       "2                                       0   \n",
       "3                                      11   \n",
       "4                                      12   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    6                         12.428571   \n",
       "1                                    0                          0.000000   \n",
       "2                                    0                          0.000000   \n",
       "3                                    7                         12.820000   \n",
       "4                                    6                         12.933333   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               11.1   \n",
       "1                                               0               11.1   \n",
       "2                                               0               16.2   \n",
       "3                                               0               11.1   \n",
       "4                                               0                7.6   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             0.6  2.02  Graduate  \n",
       "1             0.6  2.02   Dropout  \n",
       "2             0.3 -0.92   Dropout  \n",
       "3             0.6  2.02  Enrolled  \n",
       "4             2.6  0.32  Graduate  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea098bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'marital_status', 'application_mode', 'application_order',\n",
       "       'course', 'daytime/evening_attendance', 'previous_qualification',\n",
       "       'previous_qualification_(grade)', 'nacionality',\n",
       "       'mother's_qualification', 'father's_qualification',\n",
       "       'mother's_occupation', 'father's_occupation', 'admission_grade',\n",
       "       'displaced', 'educational_special_needs', 'debtor',\n",
       "       'tuition_fees_up_to_date', 'gender', 'scholarship_holder',\n",
       "       'age_at_enrollment', 'international',\n",
       "       'curricular_units_1st_sem_(credited)',\n",
       "       'curricular_units_1st_sem_(enrolled)',\n",
       "       'curricular_units_1st_sem_(evaluations)',\n",
       "       'curricular_units_1st_sem_(approved)',\n",
       "       'curricular_units_1st_sem_(grade)',\n",
       "       'curricular_units_1st_sem_(without_evaluations)',\n",
       "       'curricular_units_2nd_sem_(credited)',\n",
       "       'curricular_units_2nd_sem_(enrolled)',\n",
       "       'curricular_units_2nd_sem_(evaluations)',\n",
       "       'curricular_units_2nd_sem_(approved)',\n",
       "       'curricular_units_2nd_sem_(grade)',\n",
       "       'curricular_units_2nd_sem_(without_evaluations)', 'unemployment_rate',\n",
       "       'inflation_rate', 'gdp', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')\n",
    "\n",
    "df.columns #Phew, found the original website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec78aeb",
   "metadata": {},
   "source": [
    "### The First New Thing(s) & The Admittance of Mistakes\n",
    "\n",
    "Also, copying relevant code to run whatever:\n",
    "\n",
    "Notebook's way over the top for me. Even if it'd be meant for a non-technical audience.... way too many colors and stuff.\n",
    "\n",
    "Tangentially, when there's no formal feature engineering a bit odd tog o so in depth about the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20735e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'marital_status', 'application_mode', 'application_order', 'course']\n"
     ]
    }
   ],
   "source": [
    "print(df.select_dtypes(include=int).columns.to_list()[:5])\n",
    "categorical_features = df.select_dtypes(include=int).columns.to_list()\n",
    "continuous_features = df.select_dtypes(include=float).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb28fc",
   "metadata": {},
   "source": [
    "A very neat bit of code I just noticed. Yes! This is what I was looking for to better sift through features, especially when often I've noticed with my eda the relevant analysis and code to look at, say int. vs. float are quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a349eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016064794739226625\n",
      "-0.03339695005861841\n",
      "0.05336534850191106\n",
      "-0.03649945747047842\n",
      "0.06881799497047925\n"
     ]
    }
   ],
   "source": [
    "#This bit is so tangential, but I just realized:\n",
    "\n",
    "unique_categories = df['target'].unique()\n",
    "# print(unique_categories)\n",
    "category_to_int = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "df['target_encoded'] = df['target'].map(category_to_int)\n",
    "\n",
    "print(df['educational_special_needs'].corr(df['target_encoded']))\n",
    "print(df['curricular_units_1st_sem_(credited)'].corr(df['target_encoded']))\n",
    "print(df['curricular_units_1st_sem_(without_evaluations)'].corr(df['target_encoded']))\n",
    "print(df['curricular_units_2nd_sem_(credited)'].corr(df['target_encoded']))\n",
    "print(df['curricular_units_2nd_sem_(without_evaluations)'].corr(df['target_encoded']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405aa19",
   "metadata": {},
   "source": [
    "Yeah, I really should have been a bit more rigorous with my checking eearlier before I delete matters. Ie I negelected to check if all the special education people graduated. So, albeit a trait that rarely occurs but if it does... Pragmatically, we ended up fine in that case and likely the others, but still..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23c302c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "#Another nifty bit of code:\n",
    "discrete_features = [col for col in categorical_features if col.startswith(\"curricular\")] + [\"age_at_enrollment\"]\n",
    "print(len(discrete_features))\n",
    "#I find so much elegance in this bit of code, directly adding one feature to whatever withstands the prior list compression\n",
    "\n",
    "#Wait... these are the only discrete features?!?! Eh, not getting into that right now...\n",
    "\n",
    "#Reminder that these are simply the names of the featues.\n",
    "\n",
    "#It's much more graceful than:\n",
    "\n",
    "discrete_features = [col for col in categorical_features if col.startswith(\"curricular\")]\n",
    "discrete_features.append(\"age_at_enrollment\")\n",
    "print(len(discrete_features))\n",
    "\n",
    "#Ie the adding of lists together appends them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1284d",
   "metadata": {},
   "source": [
    "Sigh, our host made a mistake so much of the actuarial PA exam attempted to prevent - nice graphs or print outs but explain what all these numbers mean without a flood...\n",
    "\n",
    "Ie actually comment on the nature of some of them... What should we care about? Eveything?!!?\n",
    "\n",
    "So too with his visuals on counts, distribution, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b2527",
   "metadata": {},
   "source": [
    "Oh, and I took for granted the following:\n",
    "\n",
    "With various features that are, bottom-line, represented by integers, such as course number, care likely should be taken to dummify those as they are not ordinal. Might as well experiment with that (see modeling_i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113deb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oh, nicehatmap color:\n",
    "\n",
    "#cmap=\"coolwarm\"\n",
    "\n",
    "#Yeah, that will definiely make things so much easier to actually tell. Can't believe I didn't see something like\n",
    "#ths earlier. Then it's actually a a heatmap..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0614a57",
   "metadata": {},
   "source": [
    "Nice headings, summaries for each data sciency thing he's doing (such as PCA). Again, for this format I doubt it's neccesary to go into that much detail though besides just saying something like, \"Reducing the amoun of features to make the data simpler via an established technique called PCA.\"\n",
    "\n",
    "I do wonder the need for PCA when doing fancier techniques such as XGBboosting. Pragmtically, it's like, \"Try both noob!\", but even with our dummified data we have a mere 150ish for 75k entries (albeit before train/test split).\n",
    "\n",
    "Likely I can glean a lot more from this, but I'll leave it at here. of Special note is that my current (and even my submission) XGBoost is higher than what this guy got. Quite interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a448688",
   "metadata": {},
   "source": [
    "## Notebook Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ed88018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                     1\n",
       "curricular_units_2nd_sem_(credited)    0\n",
       "international                          0\n",
       "curricular_units_1st_sem_(credited)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 0] = np.nan\n",
    "\n",
    "#Kinda nice bit here, making it easier to notice the nulls:\n",
    "df.isna().sum().sort_values(ascending=False)[:4] #Then add the list referencng to make it smaller...\n",
    "#Sort ascending seems a bit overkill in retrospect as anything greater than 0 will by default be at the top..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "488f4048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And we have the following nulls:\n",
      "{'id': 1}\n"
     ]
    }
   ],
   "source": [
    "#Hmm, let's improve this:\n",
    "nulls = {df.isna().sum().index[i]:df.isna().sum()[i] for i in range(len(df.isna().sum().sort_values(ascending=False))) if df.isna().sum()[i] > 0}\n",
    "if len(nulls) > 0:\n",
    "    print(f\"And we have the following nulls:\")\n",
    "    print(nulls)\n",
    "else:\n",
    "    print(f\"Phew, we have no nulls... this time...\")\n",
    "    \n",
    "#Thanks to ChatGPT for telling me I have to use print when in the conditional, despite it being the last bit\n",
    "\n",
    "#Likely all this is a bit overkill, but eh..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98403e35",
   "metadata": {},
   "source": [
    "Unfortunately once again a deluge of information with little explanation. Ie I'll give them points for something when they wrote, \"# View the statistical description of training dataset\" before doing df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c27b95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>76517.0</td>\n",
       "      <td>38259.000000</td>\n",
       "      <td>22088.699611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19130.0</td>\n",
       "      <td>38259.0</td>\n",
       "      <td>57388.0</td>\n",
       "      <td>76517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <td>76518.0</td>\n",
       "      <td>1.111934</td>\n",
       "      <td>0.441669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_mode</th>\n",
       "      <td>76518.0</td>\n",
       "      <td>16.054419</td>\n",
       "      <td>16.682337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_order</th>\n",
       "      <td>76518.0</td>\n",
       "      <td>1.644410</td>\n",
       "      <td>1.229645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count          mean           std  min      25%      50%  \\\n",
       "id                 76517.0  38259.000000  22088.699611  1.0  19130.0  38259.0   \n",
       "marital_status     76518.0      1.111934      0.441669  1.0      1.0      1.0   \n",
       "application_mode   76518.0     16.054419     16.682337  1.0      1.0     17.0   \n",
       "application_order  76518.0      1.644410      1.229645  0.0      1.0      1.0   \n",
       "\n",
       "                       75%      max  \n",
       "id                 57388.0  76517.0  \n",
       "marital_status         1.0      6.0  \n",
       "application_mode      39.0     53.0  \n",
       "application_order      2.0      9.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T[:4] #and shoutout re. the .T... much easier to go through this way. May perclude bothering to sort\n",
    "#via categorical or not when things are this efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7170cc",
   "metadata": {},
   "source": [
    "I like their attempted classification for better visualizations (categorical vs. numerical), which we just debates, yet their approach... assuming if categorical if only 8 or more...\n",
    "\n",
    "cat_cols = [col for col in train.columns if train[col].nunique() <= 8]\n",
    "\n",
    "Seems quite untrue... ie recall father's education to give one example? Rather, the approach would seemingly be if float or not. And, even then would still need some manual inspection (per my current knowledge) consideing potential features such as SAT scores. Off hand don't see any easy way to do that. I would like to have a convenient way to do that though...\n",
    "\n",
    "--------\n",
    "Some nice graphs, especially now that he bisected the features so the type of coding to show graphs for each one isn't overbearing.\n",
    "\n",
    "Am I beinng a scoffer whe so much of the code is screaming ChatGPT to me? I personally don't mind, but at least cite it. Then again, I'm soooo curious as to the perceentage of people's workbooks that are pure ChatGPT and the like. I think it would expain the overall disapointment I feel when I look at the comments these people give to their work. Code wise obviously up the par.\n",
    "\n",
    "----\n",
    "\n",
    "Due earlier, but nice headings such as, \"X.Y Whatever\" then a nice underline underneath. Still a bit flashy, but not too much. I do think the underline is a bit much between subsections and they're short. Ie if we have a behemoth one after another...\n",
    "\n",
    "Oh, and a real fancy bar inbetween sections. I do like that. Can then justify the line a lot more when it's even clearly the change from chapter/section to the next.\n",
    "\n",
    "----\n",
    "\n",
    "Shame with his models though; our 'noobish' XGBost beat his top scorer, CatBoost, by quite a bit. Furthermore, our simple logreg with simplified other categories did better than his gradient boosting model.\n",
    "\n",
    "Yeah, no hyperparameter tuning at all...WHY?!?!?!!\n",
    "\n",
    "--------\n",
    "\n",
    "Nice bit of code with fature importance. A bit tempted to copy it. I think we can simplify it, as for sure I wouldn't bother doing it for every model.\n",
    "\n",
    "Yeah, besides that it's just like why are you showing feature importance...At least with other stuff the lack of explanation can be tolerated. But, at the very end, what are you doing?!!??! Do you want a simpler model?? Do you want to do feature engineering with those?!!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From a person at Kaggle, first obsered in Playground 4.6 Academic Success\n",
    "\n",
    "# def plot_feature_importances(model, model_name, color_scale='Reds', dataframe=None):\n",
    "#     \"\"\"\n",
    "#     Plots feature importances of a fitted random forest model.\n",
    "\n",
    "#     Parameters:\n",
    "#     model (RandomForest model): The trained random forest model.\n",
    "#     color_scale (str): Color scale for the plot.\n",
    "#     dataframe (pd.DataFrame): DataFrame used to train the model. Must not be None.\n",
    "\n",
    "#     Returns:\n",
    "#     Plotly Figure: A plot showing feature importances.\n",
    "#     \"\"\"\n",
    "#     if dataframe is None:\n",
    "#         raise ValueError(\"Dataframe cannot be None and must contain the feature names.\")\n",
    "\n",
    "#     # Extracting feature importances and sorting them\n",
    "#     importances = model.feature_importances_\n",
    "#     indices = np.argsort(importances)[::-1]\n",
    "#     feature_names = dataframe.columns\n",
    "\n",
    "#     # Creating a DataFrame for the importances\n",
    "#     feature_importances = pd.DataFrame({\n",
    "#         'Feature': feature_names[indices],\n",
    "#         'Importance': importances[indices]\n",
    "#     })\n",
    "\n",
    "#     # Plotting the feature importances\n",
    "#     fig = px.bar(feature_importances.sort_values('Importance', ascending=True), \n",
    "#                  x='Importance', \n",
    "#                  y='Feature',\n",
    "#                  title=f\"Feature Importances in {model_name}\",\n",
    "#                  labels={'Importance': 'Importance', 'Feature': 'Feature'},\n",
    "#                  height=1400,\n",
    "#                  color='Importance',\n",
    "#                  color_continuous_scale=color_scale)\n",
    "\n",
    "#     fig.update_layout(xaxis_title='Importance', yaxis_title='Feature')\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# model_name = 'Random Forest'\n",
    "# fig = plot_feature_importances(rf_model, model_name, 'Picnic', X_train)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef6c75",
   "metadata": {},
   "source": [
    "## Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a714d",
   "metadata": {},
   "source": [
    "Phew, some redemption - finally a guy that writes what he's doing.\n",
    "\n",
    "----------\n",
    "\n",
    "Interesting idea re. \"...for that much data we'll nto always do a five-fold cross-validation...\" For sure if we're doing something more lengthy like SVMs, but I found that even running many many combinations on XGBoost to not take that long. Plus to be sure I still fail to see past the argument, \"Why not?\", considering the 'time save' to be negligible.\n",
    "\n",
    "Hmm, a pie chart. Eh, guess when just 3 it's fine - plus he still had the percentages inside.\n",
    "\n",
    "\"Note that we cannot distinguish categorical features from integer features by looking at the data. We can only distinguish them by looking at the documentation!\" What a boss! Yeah, perhaps we can't have a simplified approach as we dreamed of in our youth (of 15 minutes ago).\n",
    "\n",
    "Shame he still did the barrage of distributions, but when he actually explains them!!! Plus, neat how he uses different colors for different types: integers, categories, and floats as blue, black, and green (bar, bar, histograms interestingly).\n",
    "\n",
    "Also, shame he didn't use the mask. Maybe he's not into it though. Plus, \"DISCLAIMER: It is very questionable whether one should compute correlations for categorical features, but we do it anyway.\"\n",
    "\n",
    "Oh, it just dawned on me - what's his code?!!? Sigh, I'll take the codeless explanation over code without it at least this time. Shame, as I must admit I'd prefer the later anydays - as who cares how much of a smooth criminal we're dealng wth if we have no clue how he got there (by moonwalking, excuse me).\n",
    "\n",
    "Shame too as he made the heatmap more readible by multiplyng by 10. A bit ironic considering the name of the visual though.\n",
    "\n",
    "----\n",
    "\n",
    "Interesting bit of comparing the top feature's distribution in the train/test and validatio data. Suppose it's worthy to do. Unsure how he used cirriculate units, which we do know to be the most significant. Perhaps via correlations; oh wait, that's pure unsupervised there - no target in sight...\n",
    "\n",
    "Very nice useage of decision trees to highlight pragmatically why that feature is so significan.\n",
    "\n",
    "----- \n",
    "\n",
    "Not up to it at the moment, but lkely worthwhie to make noe of his top model, ensemble (ridge) which was .002 greater than ours. Plus, what's these 'tuned' he keeps on mentioning? Furthermore, what's DART? Also, shoutout to him using extra trees.\n",
    "\n",
    "----\n",
    "\n",
    "Shoutout out again for him stating his conclusion. Besides eliminating useless, he wants to create additional.How though - do you mean via engineering or going into the field? Love how he goaded people to actually tune models. And, fun last oe, \"Find a better ensembling method.\" Likely reserved for the phders. Might be there one day, you never know...\n",
    "\n",
    "Overall I am quite pleased with his work, albit not adding any new code here; adding and cemeting my knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeedb53",
   "metadata": {},
   "source": [
    "## Notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc0fd1",
   "metadata": {},
   "source": [
    "Gah, already way to many visuals and an about me seems over the top. Especially when it's the same over the top one after every section.\n",
    "\n",
    "I will give them credit for some fancy codes, but these monster formulas/methods I'm never fond of. Recalling some of my early macros in my first internship...\n",
    "\n",
    "A lot of fluff in my opinion, but I will also laud them for a nice display of unique values. Then again, we do have the data dictionary which is essentially that. Also, will laud the nice font manipulations and backgrounds.\n",
    "\n",
    "------------\n",
    "\n",
    "Hmm, they also wanted to try to classify features by category, with a threshold, default 50, for them. Better than the 8, but still... we honestly got close to that earlier...<br> Again, like I may have wrote earlier, perhaps something like that is worthwhile as a default, then spruce up the exceptions later, but it ultimately still requires human intervention.\n",
    "\n",
    "Now, if we have objects instad of numbers, ie 'married' instead of 2, then perhaps a function/loop to log those and map them would be worthwhile. Could make that later.\n",
    "\n",
    "------------\n",
    "\n",
    "Sigh, a barrage of visuals again. Although I obviously have what to work on, even if I do print out every count, for example, I'll comment on what we're seeing... Once again a line or two of introduction - that's it...\n",
    "\n",
    "-----\n",
    "\n",
    "I feel like I've been too critical. Thankfully, we have something to praise (genuinely and again) - adressing outliers. Yes, I forgot to do that. Relevant for any numeric feature. Likely curbing or dropping this could also yield much greater accuracy. A shame, once again, though that there was no commentary at all.\n",
    "\n",
    "----\n",
    "\n",
    "Whaaaaat? By also using XGBoost .6, 400, 3, .29, col by smple .5 and a test accuracy of .852?!?!!? Must have ben some serious discrepancies between this and the final as the highest was barely over .84..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02764b12",
   "metadata": {},
   "source": [
    "## Notebook 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fb56c",
   "metadata": {},
   "source": [
    "Fancy starter visual, but was actually nice (in my opinion) as i marks different students with different images representing different features all weaving togther.\n",
    "\n",
    "---------\n",
    "\n",
    "Boss, this guy is actually describing stuff. Well, at least at the beginning....\n",
    "\n",
    "Oyyyyy. I didn't even consider the class-imbalance a potential issue. We stratified, but I assumed that when we still have a health 20ish percent in the minority we'd be fine.... Definitely worth playing with that.\n",
    "\n",
    "Worth also noting that he, and truthfully others, also checked for duplicate data. Honestly should be doing that myself. Recall the first iteration of my reddit project?!?!\n",
    "\n",
    "----\n",
    "\n",
    "Woooh, he made observations about his visuals. Albeit I'd claim some are shallow, but still... we finally found a comrade!\n",
    "\n",
    "Interesting plots where by each category, such as marital status, he directly compares the three targets. A bit overwhelming dependng upon the graph. And, ofte would need to be scaled or have their numbers on top, as many of them are overwhelming in one group and the rest are lilluputions (sp?).\n",
    "\n",
    "Unsure what he's adding with the pie chart when we already say a bar of the targets eariler.\n",
    "\n",
    "Noooooooooooooooo. He let me down with that color scheme. Albeit cool he made a custom one, but wha is that - blue to orange to green?!!?\n",
    "\n",
    "-----\n",
    "\n",
    "Of note is him keepig all the feeatures.\n",
    "\n",
    "Hmm, for his log reg he specified multiclass = 'ovr'. Likely bad I did nothing, but eh, we did wel with it...\n",
    "\n",
    "Is he note tuning his guys? Noooo.\n",
    "\n",
    "Interesting visuals with his KNN - erro rate vs k value.\n",
    "\n",
    "Also, I do like his classification report, but a shame he didn't introduce it. Furthermore, when ultimatly our final metric for Kaggle is accuracy... But still, from a tuning perspective could be the way to go about it, to get that higher accuracy, is by focusing perhaps on another metric.\n",
    "\n",
    "----\n",
    "\n",
    "Hmm, a bit interesting he's going over everything again with the holdout data re. analysis. Albeit good to check, which I took for granted I think, but to re-write everything by default..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ba51c",
   "metadata": {},
   "source": [
    "## Notebook 6\n",
    "\n",
    "Time for a final one before doing something else, with this project or another.\n",
    "\n",
    "I'll comment on the first notebook I see where I add a comment of benefit to me, whether in code or organzation.\n",
    "\n",
    "----\n",
    "\n",
    "Well, I won't hesitate to complain about \"EDA\" being just df.describe().T without a single word of explanation - feh!\n",
    "\n",
    "A number of interesting graphs, whether positive or negative, but for the sake of brevity I won't bother to comment. In short don't let your reader have epilispy (sp?) with all the colors.\n",
    "\n",
    "Interesting to play around with select cubic+ engineered featues. Unsure if XGBoost would pick it up, but at the least gotta laud him for that. However, DON\"T EVER ADD THEM per linear algebra that I don't honestly remember.\n",
    "\n",
    "----------------\n",
    "\n",
    "Guess we're done with these notebooks for now. Pragmatically I didn't try one of XGBoost's brothers, but I can't say I'm too motivated when ultimately it'll come down to, \"I can't explain it mathematically, but it works!\"\n",
    "\n",
    "Now, I did notice a bit of people get higher accuracy via many different hyperparamters, even within XGBoost, but the pragmatics of doing that seem negligible, save if the data science problem statement (which technically would be valid for Kaggle competitions) justifies using something like that.\n",
    "\n",
    "If I decide to do more competitions, which I'm debating, it does give easy github activity, to just focus on any peer notebook that isn't pounding XGBoost and the like, out of hope that they actually comment, do formal feature engineerng, etc.\n",
    "\n",
    "Perhaps I need to just find a second 'capstone' to keep myself occupied with. We'll see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2928b2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_mode</th>\n",
       "      <th>application_order</th>\n",
       "      <th>course</th>\n",
       "      <th>daytime/evening_attendance</th>\n",
       "      <th>previous_qualification</th>\n",
       "      <th>previous_qualification_(grade)</th>\n",
       "      <th>nacionality</th>\n",
       "      <th>mother's_qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_2nd_sem_(enrolled)</th>\n",
       "      <th>curricular_units_2nd_sem_(evaluations)</th>\n",
       "      <th>curricular_units_2nd_sem_(approved)</th>\n",
       "      <th>curricular_units_2nd_sem_(grade)</th>\n",
       "      <th>curricular_units_2nd_sem_(without_evaluations)</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>gdp</th>\n",
       "      <th>target</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  marital_status  application_mode  application_order  course  \\\n",
       "0   0               1                 1                  1    9238   \n",
       "1   1               1                17                  1    9238   \n",
       "2   2               1                17                  2    9254   \n",
       "3   3               1                 1                  3    9500   \n",
       "4   4               1                 1                  2    9500   \n",
       "\n",
       "   daytime/evening_attendance  previous_qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           1                       1   \n",
       "\n",
       "   previous_qualification_(grade)  nacionality  mother's_qualification  ...  \\\n",
       "0                           126.0            1                       1  ...   \n",
       "1                           125.0            1                      19  ...   \n",
       "2                           137.0            1                       3  ...   \n",
       "3                           131.0            1                      19  ...   \n",
       "4                           132.0            1                      19  ...   \n",
       "\n",
       "   curricular_units_2nd_sem_(enrolled)  \\\n",
       "0                                    6   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    8   \n",
       "4                                    7   \n",
       "\n",
       "   curricular_units_2nd_sem_(evaluations)  \\\n",
       "0                                       7   \n",
       "1                                       9   \n",
       "2                                       0   \n",
       "3                                      11   \n",
       "4                                      12   \n",
       "\n",
       "   curricular_units_2nd_sem_(approved)  curricular_units_2nd_sem_(grade)  \\\n",
       "0                                    6                         12.428571   \n",
       "1                                    0                          0.000000   \n",
       "2                                    0                          0.000000   \n",
       "3                                    7                         12.820000   \n",
       "4                                    6                         12.933333   \n",
       "\n",
       "   curricular_units_2nd_sem_(without_evaluations)  unemployment_rate  \\\n",
       "0                                               0               11.1   \n",
       "1                                               0               11.1   \n",
       "2                                               0               16.2   \n",
       "3                                               0               11.1   \n",
       "4                                               0                7.6   \n",
       "\n",
       "   inflation_rate   gdp    target  target_encoded  \n",
       "0             0.6  2.02  Graduate               0  \n",
       "1             0.6  2.02   Dropout               1  \n",
       "2             0.3 -0.92   Dropout               1  \n",
       "3             0.6  2.02  Enrolled               2  \n",
       "4             2.6  0.32  Graduate               0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
