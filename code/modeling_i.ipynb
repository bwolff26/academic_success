{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5938877",
   "metadata": {},
   "source": [
    "Unsure of what to expect. We'll drop, however, the special education and credited & without evaluation features (both 1st and 2nd) to simplify our model. See ceda_i for the reason behind this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a161fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6ef249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "import warnings #To make things cleaner...\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f71c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730a4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76518, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_mode</th>\n",
       "      <th>application_order</th>\n",
       "      <th>course</th>\n",
       "      <th>daytime/evening_attendance</th>\n",
       "      <th>previous_qualification</th>\n",
       "      <th>previous_qualification_(grade)</th>\n",
       "      <th>nacionality</th>\n",
       "      <th>mother's_qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_1st_sem_(approved)</th>\n",
       "      <th>curricular_units_1st_sem_(grade)</th>\n",
       "      <th>curricular_units_2nd_sem_(enrolled)</th>\n",
       "      <th>curricular_units_2nd_sem_(evaluations)</th>\n",
       "      <th>curricular_units_2nd_sem_(approved)</th>\n",
       "      <th>curricular_units_2nd_sem_(grade)</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>gdp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12.591250</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  marital_status  application_mode  application_order  course  \\\n",
       "0   0               1                 1                  1    9238   \n",
       "1   1               1                17                  1    9238   \n",
       "2   2               1                17                  2    9254   \n",
       "3   3               1                 1                  3    9500   \n",
       "4   4               1                 1                  2    9500   \n",
       "\n",
       "   daytime/evening_attendance  previous_qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           1                       1   \n",
       "\n",
       "   previous_qualification_(grade)  nacionality  mother's_qualification  ...  \\\n",
       "0                           126.0            1                       1  ...   \n",
       "1                           125.0            1                      19  ...   \n",
       "2                           137.0            1                       3  ...   \n",
       "3                           131.0            1                      19  ...   \n",
       "4                           132.0            1                      19  ...   \n",
       "\n",
       "   curricular_units_1st_sem_(approved)  curricular_units_1st_sem_(grade)  \\\n",
       "0                                    6                         14.500000   \n",
       "1                                    4                         11.600000   \n",
       "2                                    0                          0.000000   \n",
       "3                                    7                         12.591250   \n",
       "4                                    6                         12.933333   \n",
       "\n",
       "   curricular_units_2nd_sem_(enrolled)  \\\n",
       "0                                    6   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    8   \n",
       "4                                    7   \n",
       "\n",
       "   curricular_units_2nd_sem_(evaluations)  \\\n",
       "0                                       7   \n",
       "1                                       9   \n",
       "2                                       0   \n",
       "3                                      11   \n",
       "4                                      12   \n",
       "\n",
       "   curricular_units_2nd_sem_(approved)  curricular_units_2nd_sem_(grade)  \\\n",
       "0                                    6                         12.428571   \n",
       "1                                    0                          0.000000   \n",
       "2                                    0                          0.000000   \n",
       "3                                    7                         12.820000   \n",
       "4                                    6                         12.933333   \n",
       "\n",
       "   unemployment_rate  inflation_rate   gdp    target  \n",
       "0               11.1             0.6  2.02  Graduate  \n",
       "1               11.1             0.6  2.02   Dropout  \n",
       "2               16.2             0.3 -0.92   Dropout  \n",
       "3               11.1             0.6  2.02  Enrolled  \n",
       "4                7.6             2.6  0.32  Graduate  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')\n",
    "\n",
    "df.drop(['educational_special_needs', 'curricular_units_1st_sem_(credited)', 'curricular_units_1st_sem_(without_evaluations)', 'curricular_units_2nd_sem_(credited)', 'curricular_units_2nd_sem_(without_evaluations)'],axis = 1, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27aa849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Graduate' 'Dropout' 'Enrolled']\n"
     ]
    }
   ],
   "source": [
    "unique_categories = df['target'].unique()\n",
    "print(unique_categories)\n",
    "category_to_int = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "df['target_encoded'] = df['target'].map(category_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ed45e",
   "metadata": {},
   "source": [
    "Hmm, without having a formal data science project what to do. I suppose we'll go for default accuracy.\n",
    "\n",
    "I'll try to reserve comments for something of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc329930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target', 'id', 'target_encoded'], axis = 1) #Starting out, at least, with 'everything'. Save id of course as that adds no value.\n",
    "y = df['target_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2, #Perhaps subject to change, but we'll go with it for now\n",
    "                                                    random_state = 26, #Recall that I like this number\n",
    "                                                    stratify=y) #Lest a dispropportionate amount of one be in any cut.\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9edb642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8165452347502206 0.818086774699425\n",
      "0.815842750975745\n",
      "{'lr__C': 0.9}\n"
     ]
    }
   ],
   "source": [
    "#Generally I'll only preserve the last bit of parameters I tried in this section of the code, not bothering to record every single iteration...\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('lr', LogisticRegression(max_iter=2500))\n",
    "])\n",
    "\n",
    "pipe_params = {'lr__C' : [.85, .95, .9]\n",
    "              }\n",
    "\n",
    "gs_lrcv = GridSearchCV(pipe,\n",
    "                  param_grid=pipe_params,\n",
    "                  cv=5)\n",
    "\n",
    "gs_lrcv.fit(X_train, y_train)\n",
    "\n",
    "print(gs_lrcv.score(X_train, y_train), gs_lrcv.score(X_test, y_test))\n",
    "print(gs_lrcv.best_score_)\n",
    "print(gs_lrcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a565537",
   "metadata": {},
   "source": [
    "All ready off to a nice start. Ie the simple (albeit I took out a few features already) logistic regression already gave us an overall r2 of .816 on our train split, being slightly underfit in reality. The current leaderboards shows the very best to be at .84179 so it's not like we'd improve all that much in this case by doing something fancier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c85d8",
   "metadata": {},
   "source": [
    "Yet, we will anyways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e7448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9528212500408403 0.8261238891792996\n",
      "0.8257261443622657\n",
      "{'rfc__max_features': 'log2', 'rfc__min_samples_leaf': 2, 'rfc__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('rfc', RandomForestClassifier(random_state=26))\n",
    "])\n",
    "\n",
    "pipe_params = {'rfc__min_samples_split' : [2,3,5]\n",
    "               ,'rfc__min_samples_leaf' : [1,2,3]\n",
    "               ,'rfc__max_features' : ['sqrt', 'log2']\n",
    "              }\n",
    "#Will keep grid search to make things easier\n",
    "gs_rfc = GridSearchCV(pipe,\n",
    "                  param_grid=pipe_params,\n",
    "                  cv=None)\n",
    "\n",
    "gs_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(gs_rfc.score(X_train, y_train), gs_rfc.score(X_test, y_test))\n",
    "print(gs_rfc.best_score_)\n",
    "print(gsgs_rfc_lrcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d344ff3",
   "metadata": {},
   "source": [
    "Reminder that there's a class_weight parameter.\n",
    "\n",
    "A nice bit of improvemet with relative ease. On the topic, let's play with this a bit more as we already have an almost .01 improvment of r2 from just switching to random forests from logistic regression.\n",
    "\n",
    "Note that at the moment unless I get close to the current leaderboards I won't bother submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da0166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8321299049237103 0.8206351280710925\n",
      "0.8188322993076408\n",
      "{'svc__C': 1.0, 'svc__degree': 3, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "pipe_params = {'svc__C' : [1.0, .95, .9]\n",
    "               ,'svc__kernel' : ['rbf']\n",
    "               ,'svc__degree' : [3] #Oh, recall this only matters if your kernel is poly.\n",
    "               #,'svc__' : []\n",
    "              }\n",
    "#Will keep grid search to make things easier\n",
    "gs_svc = GridSearchCV(pipe,\n",
    "                  param_grid=pipe_params,\n",
    "                  cv=3)\n",
    "\n",
    "gs_svc.fit(X_train, y_train)\n",
    "\n",
    "print(gs_svc.score(X_train, y_train), gs_svc.score(X_test, y_test))\n",
    "print(gs_svc.best_score_)\n",
    "print(gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ccff0f",
   "metadata": {},
   "source": [
    "Aww not as accurate. Considering its runtime (30ish minutes?), and that was just with 3 cvs, we may call it here. Reminder that here also we have class weights, relevant to the potential data science problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c7b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8110726304440161 0.7978959749085206\n",
      "0.7909301576423821\n",
      "{'knn__n_neighbors': 17, 'knn__p': 2}\n"
     ]
    }
   ],
   "source": [
    "#To at least make some actual progress today I'll see if KNN gives anything useful:\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipe_params = {'knn__n_neighbors' : [17,13,9]\n",
    "               ,'knn__p' : [1,2,3]\n",
    "#                ,'knn__' : []\n",
    "#                ,'knn__' : []\n",
    "#                ,'knn__' : []\n",
    "              }\n",
    "#Will keep grid search to make things easier\n",
    "gs_knn = GridSearchCV(pipe,\n",
    "                  param_grid=pipe_params,\n",
    "                  cv=3)\n",
    "\n",
    "gs_knn.fit(X_train, y_train)\n",
    "\n",
    "print(gs_knn.score(X_train, y_train), gs_knn.score(X_test, y_test))\n",
    "print(gs_knn.best_score_)\n",
    "print(gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6af2f8",
   "metadata": {},
   "source": [
    "Also has weights, for the record.\n",
    "\n",
    "Unfortunately a worse test r2 than even our preferred default logistic regression, yet worth a try. Likely if its accuracy was a bit higher I could see opting for it as its explanability is quite nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b23e68",
   "metadata": {},
   "source": [
    "Given that the features are definitly not independent, I won't even pretend to be naive enough to use the various Naive Bayes.\n",
    "\n",
    "I suppose I'll bust out a neural net later; eh, I don't know. Part of me wants to (and on that note finally get into xgboost),\n",
    "but just in the context of the data science problem I'm findng it hard to get motivated about it. Especialy when this is meant to be a child of a passion project and temporarily final portfolio piece I really should step it up... One thing to end up wiht the logistic regression or rf, but without trying..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58101d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "{'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.4, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.004, 'reg_lambda': 1.25, 'subsample': 0.9}\n",
      "0.8308230390720691\n",
      "0.8335729221118662\n"
     ]
    }
   ],
   "source": [
    "#When it's my first time using it I don't think I can say 'reminder', but knw that the categories need to be integers. Thankfuly\n",
    "#we wrote the code for that already.\n",
    "\n",
    "xgb = XGBClassifier(random_state=26)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [.4, .5, .3]\n",
    "    ,'n_estimators': [200, 150, 250]\n",
    "    ,'max_depth': [2, 3]\n",
    "    ,'subsample': [.9]\n",
    "    ,'colsample_bytree': [1.0]\n",
    "    ,'reg_alpha': [.004]\n",
    "    ,'reg_lambda': [1.25]\n",
    "    ,'min_child_weight': [1]\n",
    "    ,'gamma': [0]\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gs_xgb.predict(X_test)\n",
    "\n",
    "print(gs_xgb.best_params_)\n",
    "print(gs_xgb.best_score_)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465e588",
   "metadata": {},
   "source": [
    "Played a bit more and got it a bit higher and quite pleased with XGBoost's performance. Still not at the top, but with my current level of motivation we'll leave it here. Even within this incredible booster, we can do much more. However, it is not skillful (save testing one's patince or ability to be satified watching Youtube or the like in the interim while the algorithim somebody else coded is running), albeit important, to tune. Furthermore, what CEO or board would get behind using such a model under the mantra us, 'Well, mathematically this approach is much more accurate than the simple logistic regressionn.\n",
    "\n",
    "Quite shocking to me that apparently this is still somewhat underfit.\n",
    "\n",
    "Regardless, it still behooves me to investigate (eventually) the top scorers methods, whether it was via XGBoost (or its cousins) or some other 'super' package such as this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
